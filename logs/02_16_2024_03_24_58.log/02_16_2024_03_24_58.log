[2024-02-16 03:24:58,520: INFO: utils: Note: NumExpr detected 20 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.]
[2024-02-16 03:24:58,521: INFO: utils: NumExpr defaulting to 8 threads.]
[2024-02-16 03:25:02,332: WARNING: module_wrapper: From C:\ProgramData\Anaconda3\lib\site-packages\keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.
]
[2024-02-16 03:25:02,808: INFO: main: >>>>>>>>>> stage Data Ingestion Stage started <<<<<<<<<<]
[2024-02-16 03:25:02,810: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-02-16 03:25:02,810: INFO: common: yaml file: config\params.yaml loaded successfully]
[2024-02-16 03:25:02,812: INFO: common: Created directory at: artifacts]
[2024-02-16 03:25:02,812: INFO: common: Created directory at: data]
[2024-02-16 03:25:02,813: INFO: data_ingestion: Raw data path is - data]
[2024-02-16 03:25:02,813: INFO: main: >>>>>>>>>> stage Data Ingestion Stage completed <<<<<<<<<<

X==========X]
[2024-02-16 03:25:02,813: INFO: main: >>>>>>>>>> stage Data Validation stage started <<<<<<<<<<]
[2024-02-16 03:25:02,814: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-02-16 03:25:02,815: INFO: common: yaml file: config\params.yaml loaded successfully]
[2024-02-16 03:25:02,815: INFO: common: Created directory at: artifacts]
[2024-02-16 03:25:02,815: INFO: common: Created directory at: artifacts/ data_validation]
[2024-02-16 03:25:02,816: INFO: main: >>>>>>>>>> stage Data Validation stage completed <<<<<<<<<<

X==========X]
[2024-02-16 03:25:02,817: INFO: main: >>>>>>>>>> stage Data transformation stage started <<<<<<<<<<]
[2024-02-16 03:25:02,818: INFO: common: yaml file: config\config.yaml loaded successfully]
[2024-02-16 03:25:02,819: INFO: common: yaml file: config\params.yaml loaded successfully]
[2024-02-16 03:25:02,819: INFO: common: Created directory at: artifacts]
[2024-02-16 03:25:02,820: INFO: common: Created directory at: artifacts/data_transformation]
[2024-02-16 03:25:02,821: INFO: data_transformation: Loaded text data from ******* Sherlock Holmes.txt ******* succcessfully]
[2024-02-16 03:25:02,821: INFO: data_transformation: Tokenizer name set]
[2024-02-16 03:25:02,822: INFO: stage_03_data_transformation: Text data imported]
[2024-02-16 03:25:02,882: INFO: stage_03_data_transformation: Text data tokenize]
[2024-02-16 03:25:02,883: INFO: stage_03_data_transformation: The text data has 8199 word index.]
[2024-02-16 03:25:02,892: INFO: stage_03_data_transformation: Text data has been splited]
[2024-02-16 03:25:02,892: INFO: stage_03_data_transformation: Path: artifacts\data_transformation\Sherlock Holmes.pkl]
[2024-02-16 03:25:02,896: INFO: stage_03_data_transformation: Tokens are saved for Sherlock Holmes]
[2024-02-16 03:25:03,049: INFO: stage_03_data_transformation: The maximum length of Input is 101]
[2024-02-16 03:25:03,225: INFO: stage_03_data_transformation: The shape of padded input sequence is (99681, 101)]
[2024-02-16 03:25:03,320: INFO: stage_03_data_transformation: The total Output shape is (99681, 8200)]
[2024-02-16 03:25:03,324: INFO: main: >>>>>>>>>> stage Data transformation stage completed <<<<<<<<<<

X==========X]
[2024-02-16 03:25:03,324: INFO: main: >>>>>>>>>> Stage Data Training stage Started <<<<<<<<<<]
[2024-02-16 03:25:03,325: INFO: main: >>>>>>>>>> Stage Data Training stage completed <<<<<<<<<<

X==========X]
